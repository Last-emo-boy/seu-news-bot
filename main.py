import asyncio
import json
from pathlib import Path
from datetime import datetime

from astrbot.api.all import *
from astrbot.api import logger
from astrbot.api.event import filter, AstrMessageEvent, MessageChain
from astrbot.api.star import Context, Star, register
from astrbot.api.message_components import Plain

from .news_db import NewsDB
from .fetchers.jwc_fetcher import JwcFetcher
from .fetchers.sfl_fetcher import SflFetcher
from .fetchers.electronic_fetcher import ElectronicFetcher

# è‡ªåŠ¨é€šçŸ¥æŒä¹…åŒ–æ–‡ä»¶è·¯å¾„
AUTO_NOTIFY_FILE = Path(__file__).parent / "auto_notify.json"

def load_auto_notify_origins():
    if AUTO_NOTIFY_FILE.exists():
        try:
            with open(AUTO_NOTIFY_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                if isinstance(data, list):
                    logger.info(f"åŠ è½½è‡ªåŠ¨é€šçŸ¥åˆ—è¡¨ï¼š{data}")
                    return set(data)
        except Exception as e:
            logger.error(f"åŠ è½½è‡ªåŠ¨é€šçŸ¥åˆ—è¡¨å¤±è´¥ï¼š{str(e)}")
    return set()

def save_auto_notify_origins(origins: set):
    try:
        with open(AUTO_NOTIFY_FILE, "w", encoding="utf-8") as f:
            json.dump(list(origins), f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜è‡ªåŠ¨é€šçŸ¥åˆ—è¡¨æˆåŠŸï¼š{list(origins)}")
    except Exception as e:
        logger.error(f"ä¿å­˜è‡ªåŠ¨é€šçŸ¥åˆ—è¡¨å¤±è´¥ï¼š{str(e)}")

@register("astrbot_plugin_seu_news", "YourName", "æ–°é—»è®¢é˜…ä¸æŸ¥è¯¢æ’ä»¶ï¼Œæ¨¡å—åŒ–æŠ“å–å¤šä¸ªæ¥æº", "1.0.0", "https://github.com/yourrepo/astrbot_plugin_seu_news")
class NewsPlugin(Star):
    def __init__(self, context: Context, config: dict):
        """
        æ’ä»¶åˆå§‹åŒ–æ—¶æ¥æ”¶é…ç½®æ–‡ä»¶ï¼ˆ_conf_schema.jsonï¼‰ï¼Œæ”¯æŒé…ç½®é¡¹ï¼š
          - check_interval: å®šæ—¶æ£€æŸ¥æ–°é—»æ›´æ–°çš„é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 3600 ç§’
        """
        super().__init__(context)
        self.config = config
        self.db = NewsDB()
        # åˆå§‹åŒ–å„ä¸ªæ–°é—»æŠ“å–å™¨
        self.fetchers = [JwcFetcher(), SflFetcher(), ElectronicFetcher()]
        # è‡ªåŠ¨é€šçŸ¥è®¢é˜…åˆ—è¡¨ï¼ˆä½¿ç”¨ unified_msg_origin ä½œä¸ºæ ‡è¯†ï¼‰
        self.auto_notify_origins = load_auto_notify_origins()
        interval = self.config.get("check_interval", 3600)
        logger.info(f"æ–°é—»æ’ä»¶å¯åŠ¨ï¼Œå®šæ—¶æ£€æŸ¥é—´éš”è®¾ç½®ä¸º {interval} ç§’")
        asyncio.create_task(self.scheduled_check(interval=interval))
    
    async def scheduled_check(self, interval: int):
        """
        å®šæ—¶ä»»åŠ¡ï¼šå®šæœŸè°ƒç”¨æ‰€æœ‰æŠ“å–å™¨è¿›è¡Œå¢é‡æ›´æ–°ï¼Œ
        æ¯ä¸ªæŠ“å–å™¨å°†æ¥æ”¶ä¸€ä¸ªæœ€æ–°æ—¥æœŸå­—å…¸ï¼ˆé”®ä¸ºé¢‘é“ï¼Œå€¼ä¸ºæœ€æ–°æ—¥æœŸï¼Œæ ¼å¼ "YYYY-MM-DD"ï¼‰ï¼Œ
        ä»…è¿”å›å‘å¸ƒæ—¶é—´ä¸¥æ ¼å¤§äºå¯¹åº”æœ€æ–°æ—¥æœŸçš„æ–°é—»ï¼Œç„¶åå†™å…¥æ•°æ®åº“ï¼Œ
        å¹¶å‘æ‰€æœ‰è‡ªåŠ¨è®¢é˜…ä¼šè¯æ¨é€æ–°æ–°é—»ã€‚
        """
        while True:
            logger.info("ã€å®šæ—¶ä»»åŠ¡ã€‘å¼€å§‹å¢é‡æ›´æ–°æ£€æŸ¥")
            new_news = []
            for fetcher in self.fetchers:
                try:
                    # ä¸ºå½“å‰æŠ“å–å™¨æ„å»ºæœ€æ–°æ—¥æœŸå­—å…¸
                    latest_dates = {}
                    for channel in fetcher.categories.keys():
                        key = f"{fetcher.source}:{channel}"
                        ld = self.db.get_latest_date(key)
                        if ld:
                            try:
                                ld_str = ld.strip()[:10]
                                latest_dates[channel] = ld_str
                            except Exception as e:
                                logger.error(f"ã€å®šæ—¶ä»»åŠ¡ã€‘è§£ææ•°æ®åº“æœ€æ–°æ—¥æœŸå¤±è´¥ï¼š{ld} é”™è¯¯ï¼š{str(e)}")
                    logger.info(f"ã€å®šæ—¶ä»»åŠ¡ã€‘{fetcher.__class__.__name__} æœ€æ–°æ—¥æœŸå­—å…¸ï¼š{latest_dates}")
                    # è°ƒç”¨ fetch_news æ—¶ä¼ å…¥æœ€æ–°æ—¥æœŸå­—å…¸
                    news = await fetcher.fetch_news(force_update=False, latest_dates=latest_dates)
                    logger.info(f"{fetcher.__class__.__name__} è·å–åˆ° {len(news)} æ¡æ–°é—»")
                    new_news.extend(news)
                except Exception as e:
                    logger.error(f"ã€å®šæ—¶ä»»åŠ¡ã€‘{fetcher.__class__.__name__} æŠ“å–æ–°é—»å¤±è´¥ï¼š{str(e)}")
            # å†™å…¥æ•°æ®åº“
            for record in new_news:
                source, channel, title, url, pub_date = record
                key = f"{source}:{channel}"
                try:
                    self.db.insert_news([record], key=key)
                    logger.info(f"ã€å®šæ—¶ä»»åŠ¡ã€‘æ’å…¥æ–°æ–°é—»ï¼š{title} ({url})")
                except Exception as e:
                    logger.error(f"ã€å®šæ—¶ä»»åŠ¡ã€‘æ’å…¥å¤±è´¥ï¼š{title} ({url}) é”™è¯¯ï¼š{str(e)}")
            logger.info(f"ã€å®šæ—¶ä»»åŠ¡ã€‘å¢é‡æ›´æ–°å…±æ£€æµ‹åˆ° {len(new_news)} æ¡æ–°æ–°é—»")
            # è‡ªåŠ¨é€šçŸ¥
            if new_news and self.auto_notify_origins:
                msg_text = f"æ£€æµ‹åˆ° {len(new_news)} æ¡æ–°æ–°é—»ï¼š\n\n"
                for src, cat, title, url, date_str in new_news:
                    msg_text += f"ã€{src} - {cat}ã€‘ {title}\né“¾æ¥ï¼š{url}\nå‘å¸ƒæ—¥æœŸï¼š{date_str}\n\n"
                chain = MessageChain().message(msg_text)
                for origin in self.auto_notify_origins:
                    try:
                        await self.context.send_message(origin, chain)
                        logger.info(f"ã€è‡ªåŠ¨é€šçŸ¥ã€‘å·²å‘ {origin} æ¨é€æ–°æ–°é—»")
                    except Exception as e:
                        logger.error(f"ã€è‡ªåŠ¨é€šçŸ¥ã€‘å‘é€æ¶ˆæ¯åˆ° {origin} å¤±è´¥ï¼š{str(e)}")
            else:
                logger.info("ã€å®šæ—¶ä»»åŠ¡ã€‘æ— æ–°æ–°é—»æˆ–æ— è‡ªåŠ¨è®¢é˜…ä¼šè¯")
            logger.info(f"ã€å®šæ—¶ä»»åŠ¡ã€‘ç­‰å¾… {interval} ç§’åè¿›è¡Œä¸‹ä¸€æ¬¡æ›´æ–°æ£€æŸ¥")
            await asyncio.sleep(interval)
    
    @filter.command("news update")
    async def news_update(self, event: AstrMessageEvent):
        """
        æŒ‡ä»¤: /news update
        å¼ºåˆ¶å…¨é‡æŠ“å–æ–°é—»ï¼ˆä¸è¿›è¡Œå¢é‡è¿‡æ»¤ï¼‰ï¼Œå¹¶åé¦ˆæŠ“å–æ•°é‡ã€‚
        """
        logger.info("ã€å…¨é‡æ›´æ–°ã€‘å¼€å§‹å…¨é‡æŠ“å–æ–°é—»ä»»åŠ¡")
        all_news = []
        for fetcher in self.fetchers:
            try:
                news = await fetcher.fetch_news(force_update=True)
                logger.info(f"{fetcher.__class__.__name__} è·å–åˆ° {len(news)} æ¡æ–°é—»")
                all_news.extend(news)
            except Exception as e:
                logger.error(f"{fetcher.__class__.__name__} æŠ“å–æ–°é—»å¤±è´¥ï¼š{str(e)}")
        inserted_count = 0
        for record in all_news:
            source, channel, title, url, pub_date = record
            key = f"{source}:{channel}"
            try:
                self.db.insert_news([record], key=key)
                inserted_count += 1
                logger.info(f"ã€å…¨é‡æ›´æ–°ã€‘æ’å…¥æ–°é—»æˆåŠŸï¼š{title} ({url})")
            except Exception as e:
                logger.error(f"ã€å…¨é‡æ›´æ–°ã€‘æ’å…¥æ–°é—»å¤±è´¥ï¼š{title} ({url}) é”™è¯¯ï¼š{str(e)}")
        msg = f"å…¨é‡æ›´æ–°å®Œæˆï¼Œå…±æ›´æ–° {inserted_count} æ¡æ–°é—»ã€‚"
        logger.info(f"ã€å…¨é‡æ›´æ–°ã€‘{msg}")
        yield event.plain_result(msg)
    
    @filter.command("news auto")
    async def news_auto_subscribe(self, event: AstrMessageEvent):
        """
        æŒ‡ä»¤: /news auto
        å°†å½“å‰ä¼šè¯åŠ å…¥è‡ªåŠ¨æ›´æ–°é€šçŸ¥åˆ—è¡¨ï¼ˆæŒä¹…åŒ–ï¼‰ã€‚
        """
        origin = event.unified_msg_origin
        if origin in self.auto_notify_origins:
            yield event.plain_result("å½“å‰ä¼šè¯å·²åœ¨è‡ªåŠ¨æ›´æ–°åˆ—è¡¨ä¸­ã€‚")
        else:
            self.auto_notify_origins.add(origin)
            save_auto_notify_origins(self.auto_notify_origins)
            logger.info(f"ã€è‡ªåŠ¨è®¢é˜…ã€‘ä¼šè¯ {origin} åŠ å…¥è‡ªåŠ¨æ›´æ–°é€šçŸ¥åˆ—è¡¨")
            yield event.plain_result("å·²å°†å½“å‰ä¼šè¯åŠ å…¥è‡ªåŠ¨æ›´æ–°é€šçŸ¥åˆ—è¡¨ã€‚")
    
    @filter.command("news auto off")
    async def news_auto_unsubscribe(self, event: AstrMessageEvent):
        """
        æŒ‡ä»¤: /news auto off
        å°†å½“å‰ä¼šè¯ä»è‡ªåŠ¨æ›´æ–°é€šçŸ¥åˆ—è¡¨ä¸­ç§»é™¤ï¼ˆæŒä¹…åŒ–ï¼‰ã€‚
        """
        origin = event.unified_msg_origin
        # æ³¨æ„ï¼šè¿™é‡Œå¦‚æœå‡ºç°æ‹¼å†™é”™è¯¯ï¼Œè¯·ç¡®ä¿ä½¿ç”¨ unified_msg_origin
        origin = event.unified_msg_origin
        if origin in self.auto_notify_origins:
            self.auto_notify_origins.remove(origin)
            save_auto_notify_origins(self.auto_notify_origins)
            logger.info(f"ã€è‡ªåŠ¨è®¢é˜…ã€‘ä¼šè¯ {origin} ä»è‡ªåŠ¨æ›´æ–°é€šçŸ¥åˆ—è¡¨ä¸­ç§»é™¤")
            yield event.plain_result("å·²å°†å½“å‰ä¼šè¯ç§»é™¤è‡ªåŠ¨æ›´æ–°é€šçŸ¥åˆ—è¡¨ã€‚")
        else:
            yield event.plain_result("å½“å‰ä¼šè¯ä¸åœ¨è‡ªåŠ¨æ›´æ–°åˆ—è¡¨ä¸­ã€‚")
    
    @filter.command("news")
    async def get_news(self, event: AstrMessageEvent, 
                       source: str = None, 
                       channel: str = None, 
                       page: int = 1, 
                       keyword: str = None, 
                       start_date: str = None, 
                       end_date: str = None):
        """
        æŒ‡ä»¤: /news
        æŸ¥è¯¢æ–°é—»è®°å½•ï¼Œå¹¶å…ˆæ‰§è¡Œä¸€æ¬¡å¢é‡æ›´æ–°æ£€æŸ¥ï¼ˆä»…æ£€æµ‹æ–°æ•°æ®ï¼‰ï¼Œç„¶åä»æ•°æ®åº“æŸ¥è¯¢æœ€æ–°ç»“æœã€‚

        å‚æ•°ï¼ˆé¡ºåºä¾æ¬¡ä¸ºï¼‰ï¼šsource, channel, page, keyword, start_date, end_date
          - source: å¯é€‰ï¼Œæ–°é—»æ¥æºï¼ˆä¾‹å¦‚ "æ•™åŠ¡å¤„"ï¼‰
          - channel: å¯é€‰ï¼Œæ ç›®ï¼ˆä¾‹å¦‚ "zxdt"ï¼‰
          - page: é¡µç ï¼Œé»˜è®¤ä¸º 1ï¼Œæ¯é¡µæ˜¾ç¤º 5 æ¡æ–°é—»
          - keyword: å¯é€‰ï¼Œæ ‡é¢˜å…³é”®è¯è¿‡æ»¤
          - start_date: å¯é€‰ï¼Œèµ·å§‹å‘å¸ƒæ—¥æœŸï¼ˆæ ¼å¼ YYYY-MM-DDï¼‰
          - end_date: å¯é€‰ï¼Œç»“æŸå‘å¸ƒæ—¥æœŸï¼ˆæ ¼å¼ YYYY-MM-DDï¼‰
        """
        logger.info("ã€æŸ¥è¯¢ã€‘æ‰§è¡Œ /news æŒ‡ä»¤å‰è¿›è¡Œå¢é‡æ›´æ–°æ£€æŸ¥")
        # æ‰§è¡Œä¸€æ¬¡å¢é‡æ›´æ–°æ£€æŸ¥ï¼šå¯¹äºæ‰€æœ‰æŠ“å–å™¨ï¼Œä¼ å…¥ force_update=False
        for fetcher in self.fetchers:
            try:
                # æ„å»ºæœ€æ–°æ—¥æœŸå­—å…¸
                latest_dates = {}
                for ch in fetcher.categories.keys():
                    key = f"{fetcher.source}:{ch}"
                    ld = self.db.get_latest_date(key)
                    if ld:
                        try:
                            ld_str = ld.strip()[:10]
                            latest_dates[ch] = ld_str
                        except Exception as e:
                            logger.error(f"ã€æŸ¥è¯¢ã€‘è§£ææœ€æ–°æ—¥æœŸå¤±è´¥ï¼š{ld} é”™è¯¯ï¼š{str(e)}")
                logger.info(f"ã€æŸ¥è¯¢ã€‘{fetcher.__class__.__name__} æœ€æ–°æ—¥æœŸå­—å…¸ï¼š{latest_dates}")
                news = await fetcher.fetch_news(force_update=False, latest_dates=latest_dates)
                for record in news:
                    source_, channel_, title, url, pub_date = record
                    key = f"{source_}:{channel_}"
                    latest_date = self.db.get_latest_date(key)
                    latest_dt = None
                    if latest_date:
                        try:
                            latest_dt = datetime.strptime(latest_date.strip()[:10], "%Y-%m-%d")
                        except Exception as e:
                            logger.error(f"ã€æŸ¥è¯¢ã€‘æœ€æ–°æ—¥æœŸè§£æå¤±è´¥ï¼š{latest_date} é”™è¯¯ï¼š{str(e)}")
                    try:
                        record_dt = datetime.strptime(pub_date.strip()[:10], "%Y-%m-%d")
                    except Exception as e:
                        logger.error(f"ã€æŸ¥è¯¢ã€‘æ–°é—»æ—¥æœŸè§£æå¤±è´¥ï¼š{pub_date} é”™è¯¯ï¼š{str(e)}")
                        record_dt = None
                    if latest_dt is None or (record_dt is not None and record_dt > latest_dt):
                        try:
                            self.db.insert_news([record], key=key)
                            logger.info(f"ã€æŸ¥è¯¢ã€‘æ’å…¥æ–°æ–°é—»ï¼š{title} ({url})")
                        except Exception as e:
                            logger.error(f"ã€æŸ¥è¯¢ã€‘æ’å…¥å¤±è´¥ï¼š{title} ({url}) é”™è¯¯ï¼š{str(e)}")
            except Exception as e:
                logger.error(f"ã€æŸ¥è¯¢ã€‘{fetcher.__class__.__name__} æŠ“å–æ–°é—»å¤±è´¥ï¼š{str(e)}")
        per_page = 5
        results = self.db.get_news(source=source, channel=channel, page=page, per_page=per_page, 
                                   keyword=keyword, start_date=start_date, end_date=end_date)
        logger.info(f"ã€æŸ¥è¯¢ã€‘æŸ¥è¯¢æ–°é—»: source={source}, channel={channel}, page={page}, keyword={keyword}, start_date={start_date}, end_date={end_date} -> {len(results)} æ¡è®°å½•")
        if not results:
            yield event.plain_result("æš‚æ— æ›´å¤šæ–°é—»")
            return
        
        response = event.make_result().message(f"ğŸ“° æ–°é—»æŸ¥è¯¢ç»“æœï¼ˆç¬¬ {page} é¡µï¼‰\n")
        for idx, item in enumerate(results, 1):
            response = response.message(f"{idx}. ã€{item[0]} - {item[1]}ã€‘{item[2]}\né“¾æ¥ï¼š{item[3]}\nå‘å¸ƒæ—¥æœŸï¼š{item[4]}\n\n")
        if len(results) == per_page:
            next_cmd = f"/news {source or ''} {channel or ''} {page+1} {keyword or ''} {start_date or ''} {end_date or ''}"
            response = response.message(f"å‘é€ {next_cmd.strip()} æŸ¥çœ‹ä¸‹ä¸€é¡µ")
        yield response

    async def terminate(self):
        self.db.close()
