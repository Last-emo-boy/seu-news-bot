import asyncio
import json
from pathlib import Path
from datetime import datetime

from astrbot.api.all import *
from astrbot.api import logger
from astrbot.api.event import filter, AstrMessageEvent, MessageChain
from astrbot.api.star import Context, Star, register
from astrbot.api.message_components import Plain

from .news_db import NewsDB
from .fetchers.jwc_fetcher import JwcFetcher
from .fetchers.sfl_fetcher import SflFetcher
from .fetchers.electronic_fetcher import ElectronicFetcher

# è‡ªåŠ¨é€šçŸ¥æŒä¹…åŒ–æ–‡ä»¶è·¯å¾„
AUTO_NOTIFY_FILE = Path(__file__).parent / "auto_notify.json"

def load_auto_notify_origins():
    if AUTO_NOTIFY_FILE.exists():
        try:
            with open(AUTO_NOTIFY_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                if isinstance(data, list):
                    logger.info(f"åŠ è½½è‡ªåŠ¨é€šçŸ¥åˆ—è¡¨ï¼š{data}")
                    return set(data)
        except Exception as e:
            logger.exception(f"åŠ è½½è‡ªåŠ¨é€šçŸ¥åˆ—è¡¨å¤±è´¥ï¼š{e}")
    return set()

def save_auto_notify_origins(origins: set):
    try:
        with open(AUTO_NOTIFY_FILE, "w", encoding="utf-8") as f:
            json.dump(list(origins), f, ensure_ascii=False, indent=2)
        logger.info(f"ä¿å­˜è‡ªåŠ¨é€šçŸ¥åˆ—è¡¨æˆåŠŸï¼š{list(origins)}")
    except Exception as e:
        logger.exception(f"ä¿å­˜è‡ªåŠ¨é€šçŸ¥åˆ—è¡¨å¤±è´¥ï¼š{e}")

@register("astrbot_plugin_seu_news", "YourName", "æ–°é—»è®¢é˜…ä¸æŸ¥è¯¢æ’ä»¶ï¼Œæ¨¡å—åŒ–æŠ“å–å¤šä¸ªæ¥æº", "1.0.0", "https://github.com/yourrepo/astrbot_plugin_seu_news")
class NewsPlugin(Star):
    def __init__(self, context: Context, config: dict):
        """
        æ’ä»¶åˆå§‹åŒ–æ—¶æ¥æ”¶é…ç½®æ–‡ä»¶ï¼ˆé€šè¿‡ _conf_schema.jsonï¼‰ï¼Œæ”¯æŒé…ç½®é¡¹ï¼š
          - check_interval: æ£€æŸ¥æ›´æ–°çš„é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 3600 ç§’
        """
        super().__init__(context)
        self.config = config
        self.db = NewsDB()
        # åˆå§‹åŒ–æŠ“å–å™¨åˆ—è¡¨
        self.fetchers = [JwcFetcher(), SflFetcher(), ElectronicFetcher()]
        # è‡ªåŠ¨é€šçŸ¥è®¢é˜…åˆ—è¡¨ï¼ˆä»¥ unified_msg_origin ä½œä¸ºæ ‡è¯†ï¼‰
        self.auto_notify_origins = load_auto_notify_origins()
        self.check_interval = self.config.get("check_interval", 3600)
        logger.info(f"æ–°é—»æ’ä»¶å¯åŠ¨ï¼Œæ›´æ–°é—´éš”è®¾ç½®ä¸º {self.check_interval} ç§’")
        asyncio.create_task(self.scheduled_check())

    async def scheduled_check(self):
        """
        å®šæ—¶ä»»åŠ¡ï¼šå®šæœŸè°ƒç”¨æ‰€æœ‰æŠ“å–å™¨æŠ“å–æ–°é—»ï¼Œ
        å¹¶å‘å†™å…¥æ•°æ®åº“ã€å¹¶å‘æ¨é€é€šçŸ¥ï¼ŒåŒæ—¶è®°å½•è¯¦ç»†æ—¥å¿—ä¾¿äºç›‘æ§å’Œè°ƒè¯•ã€‚
        """
        while True:
            logger.info("å¼€å§‹å®šæ—¶æŠ“å–æ–°é—»ä»»åŠ¡")
            all_news = []
            try:
                # å¹¶å‘è°ƒç”¨æ‰€æœ‰æŠ“å–å™¨
                fetch_tasks = [asyncio.create_task(fetcher.fetch_news()) for fetcher in self.fetchers]
                results = await asyncio.gather(*fetch_tasks, return_exceptions=True)
                for idx, result in enumerate(results):
                    fetcher = self.fetchers[idx]
                    if isinstance(result, Exception):
                        logger.exception(f"{fetcher.__class__.__name__} æŠ“å–æ–°é—»å¤±è´¥ï¼š{result}")
                    else:
                        logger.info(f"{fetcher.__class__.__name__} è·å–åˆ° {len(result)} æ¡æ–°é—»")
                        all_news.extend(result)
            except Exception as e:
                logger.exception(f"å®šæ—¶æŠ“å–ä»»åŠ¡å‡ºé”™ï¼š{e}")
            
            # æ•°æ®åº“æ’å…¥æ–°é—»è®°å½•
            inserted_count = 0
            for record in all_news:
                source, channel, title, url, pub_date = record
                key = f"{source}:{channel}"
                try:
                    self.db.insert_news([record], key=key)
                    inserted_count += 1
                    logger.debug(f"æ’å…¥æ–°é—»æˆåŠŸï¼š{title} ({url})")
                except Exception as e:
                    logger.exception(f"æ’å…¥æ–°é—»å¤±è´¥ï¼š{title} ({url})ï¼Œé”™è¯¯ï¼š{e}")
            logger.info(f"æœ¬æ¬¡å®šæ—¶æŠ“å–å¤„ç† {len(all_news)} æ¡æ–°é—»ï¼ŒæˆåŠŸæ’å…¥ {inserted_count} æ¡æ–°è®°å½•")
            
            # è‡ªåŠ¨é€šçŸ¥è®¢é˜…ä¼šè¯ï¼ˆå¹¶å‘æ¨é€ï¼‰
            if all_news and self.auto_notify_origins:
                msg_text = f"æ£€æµ‹åˆ° {len(all_news)} æ¡æœ€æ–°æ–°é—»ï¼š\n\n"
                for src, cat, title, url, date_str in all_news:
                    msg_text += f"ã€{src} - {cat}ã€‘ {title}\né“¾æ¥ï¼š{url}\nå‘å¸ƒæ—¥æœŸï¼š{date_str}\n\n"
                chain = MessageChain().message(msg_text)
                notify_tasks = [self.send_notification(origin, chain) for origin in self.auto_notify_origins]
                await asyncio.gather(*notify_tasks)
            else:
                logger.info("æœ¬æ¬¡æŠ“å–æœªå‘ç°æ–°æ–°é—»æˆ–æ— è‡ªåŠ¨è®¢é˜…ä¼šè¯")
            
            logger.info(f"ç­‰å¾… {self.check_interval} ç§’åè¿›è¡Œä¸‹ä¸€æ¬¡æŠ“å–")
            await asyncio.sleep(self.check_interval)
    
    async def send_notification(self, origin, chain):
        try:
            await self.context.send_message(origin, chain)
            logger.info(f"å·²å‘ {origin} æ¨é€æ–°æ–°é—»")
        except Exception as e:
            logger.exception(f"å‘é€æ¶ˆæ¯åˆ° {origin} å¤±è´¥ï¼š{e}")
    
    @filter.command("news update")
    async def news_update(self, event: AstrMessageEvent):
        """
        æŒ‡ä»¤: /news update
        å¼ºåˆ¶å…¨é‡æŠ“å–æ–°é—»ï¼ˆå¿½ç•¥æ•°æ®åº“æœ€æ–°è®°å½•ï¼‰ï¼Œå¹¶åé¦ˆæŠ“å–æ•°é‡ã€‚
        """
        all_news = []
        logger.info("å¼€å§‹å…¨é‡æ›´æ–°æ–°é—»ä»»åŠ¡")
        try:
            fetch_tasks = [asyncio.create_task(fetcher.fetch_news()) for fetcher in self.fetchers]
            results = await asyncio.gather(*fetch_tasks, return_exceptions=True)
            for idx, result in enumerate(results):
                fetcher = self.fetchers[idx]
                if isinstance(result, Exception):
                    logger.exception(f"{fetcher.__class__.__name__} æŠ“å–æ–°é—»å¤±è´¥ï¼š{result}")
                else:
                    logger.info(f"{fetcher.__class__.__name__} è·å–åˆ° {len(result)} æ¡æ–°é—»")
                    all_news.extend(result)
        except Exception as e:
            logger.exception(f"å…¨é‡æ›´æ–°ä»»åŠ¡å‡ºé”™ï¼š{e}")
        
        inserted_count = 0
        for record in all_news:
            source, channel, title, url, pub_date = record
            key = f"{source}:{channel}"
            try:
                self.db.insert_news([record], key=key)
                inserted_count += 1
                logger.debug(f"æ’å…¥æ–°é—»æˆåŠŸï¼š{title} ({url})")
            except Exception as e:
                logger.exception(f"æ’å…¥æ–°é—»å¤±è´¥ï¼š{title} ({url})ï¼Œé”™è¯¯ï¼š{e}")
        msg = f"å…¨é‡æ›´æ–°å®Œæˆï¼Œå…±æ›´æ–° {len(all_news)} æ¡æ–°é—»ï¼ŒæˆåŠŸæ’å…¥ {inserted_count} æ¡è®°å½•ã€‚"
        logger.info(msg)
        yield event.plain_result(msg)
    
    @filter.command("news auto")
    async def news_auto_subscribe(self, event: AstrMessageEvent):
        """
        æŒ‡ä»¤: /news auto
        å°†å½“å‰ä¼šè¯åŠ å…¥è‡ªåŠ¨æ›´æ–°é€šçŸ¥åˆ—è¡¨ï¼ˆæŒä¹…åŒ–ï¼‰ã€‚
        """
        origin = event.unified_msg_origin
        if origin in self.auto_notify_origins:
            yield event.plain_result("å½“å‰ä¼šè¯å·²åœ¨è‡ªåŠ¨æ›´æ–°åˆ—è¡¨ä¸­ã€‚")
        else:
            self.auto_notify_origins.add(origin)
            save_auto_notify_origins(self.auto_notify_origins)
            logger.info(f"ä¼šè¯ {origin} åŠ å…¥è‡ªåŠ¨æ›´æ–°é€šçŸ¥åˆ—è¡¨")
            yield event.plain_result("å·²å°†å½“å‰ä¼šè¯åŠ å…¥è‡ªåŠ¨æ›´æ–°é€šçŸ¥åˆ—è¡¨ã€‚")
    
    @filter.command("news auto off")
    async def news_auto_unsubscribe(self, event: AstrMessageEvent):
        """
        æŒ‡ä»¤: /news auto off
        å°†å½“å‰ä¼šè¯ä»è‡ªåŠ¨æ›´æ–°é€šçŸ¥åˆ—è¡¨ä¸­ç§»é™¤ï¼ˆæŒä¹…åŒ–ï¼‰ã€‚
        """
        origin = event.unified_msg_origin
        if origin in self.auto_notify_origins:
            self.auto_notify_origins.remove(origin)
            save_auto_notify_origins(self.auto_notify_origins)
            logger.info(f"ä¼šè¯ {origin} ä»è‡ªåŠ¨æ›´æ–°é€šçŸ¥åˆ—è¡¨ä¸­ç§»é™¤")
            yield event.plain_result("å·²å°†å½“å‰ä¼šè¯ç§»é™¤è‡ªåŠ¨æ›´æ–°é€šçŸ¥åˆ—è¡¨ã€‚")
        else:
            yield event.plain_result("å½“å‰ä¼šè¯ä¸åœ¨è‡ªåŠ¨æ›´æ–°åˆ—è¡¨ä¸­ã€‚")
    
    @filter.command("news")
    async def get_news(self, event: AstrMessageEvent, 
                       source: str = None, 
                       channel: str = None, 
                       page: int = 1, 
                       keyword: str = None, 
                       start_date: str = None, 
                       end_date: str = None):
        """
        æŒ‡ä»¤: /news
        æŸ¥è¯¢æ–°é—»è®°å½•ã€‚

        å‚æ•°ï¼ˆé¡ºåºä¾æ¬¡ä¸ºï¼‰ï¼šsource, channel, page, keyword, start_date, end_date
          - source: å¯é€‰ï¼Œæ–°é—»æ¥æºï¼ˆä¾‹å¦‚ "æ•™åŠ¡å¤„"ï¼‰
          - channel: å¯é€‰ï¼Œæ ç›®ï¼ˆä¾‹å¦‚ "zxdt"ï¼‰
          - page: é¡µç ï¼Œé»˜è®¤ä¸º 1ï¼Œæ¯é¡µæ˜¾ç¤º 5 æ¡æ–°é—»
          - keyword: å¯é€‰ï¼Œæ ‡é¢˜å…³é”®è¯è¿‡æ»¤
          - start_date: å¯é€‰ï¼Œèµ·å§‹å‘å¸ƒæ—¥æœŸï¼ˆæ ¼å¼ YYYY-MM-DDï¼‰
          - end_date: å¯é€‰ï¼Œç»“æŸå‘å¸ƒæ—¥æœŸï¼ˆæ ¼å¼ YYYY-MM-DDï¼‰
        """
        per_page = 5
        results = self.db.get_news(source=source, channel=channel, page=page, per_page=per_page, 
                                   keyword=keyword, start_date=start_date, end_date=end_date)
        logger.info(f"æŸ¥è¯¢æ–°é—»: source={source}, channel={channel}, page={page}, keyword={keyword}, start_date={start_date}, end_date={end_date} -> {len(results)} æ¡è®°å½•")
        if not results:
            yield event.plain_result("æš‚æ— æ›´å¤šæ–°é—»")
            return
        
        response = event.make_result().message(f"ğŸ“° æ–°é—»æŸ¥è¯¢ç»“æœï¼ˆç¬¬ {page} é¡µï¼‰\n")
        for idx, item in enumerate(results, 1):
            response = response.message(f"{idx}. ã€{item[0]} - {item[1]}ã€‘{item[2]}\né“¾æ¥ï¼š{item[3]}\nå‘å¸ƒæ—¥æœŸï¼š{item[4]}\n\n")
        if len(results) == per_page:
            next_cmd = f"/news {source or ''} {channel or ''} {page+1} {keyword or ''} {start_date or ''} {end_date or ''}"
            response = response.message(f"å‘é€ {next_cmd.strip()} æŸ¥çœ‹ä¸‹ä¸€é¡µ")
        yield response

    async def terminate(self):
        self.db.close()
