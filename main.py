import asyncio
import aiohttp
import json
from pathlib import Path
from astrbot.api.all import *
from bs4 import BeautifulSoup
from datetime import datetime
from .news_db import NewsDB

BASE_URL = "https://jwc.seu.edu.cn"
# å¾…çˆ¬å–çš„å„ä¸ªæ ç›®
PATHS = ["zxdt", "jwxx", "jxgl", "gjjl", "sjjx", "cbxx", "jxyj"]
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
}

# å®šä¹‰æŒä¹…åŒ–è‡ªåŠ¨é€šçŸ¥åˆ—è¡¨çš„ JSON æ–‡ä»¶è·¯å¾„
AUTO_NOTIFY_FILE = Path(__file__).parent / "auto_notify.json"

def load_auto_notify_origins():
    if AUTO_NOTIFY_FILE.exists():
        try:
            with open(AUTO_NOTIFY_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                if isinstance(data, list):
                    return set(data)
        except Exception:
            return set()
    return set()

def save_auto_notify_origins(origins: set):
    with open(AUTO_NOTIFY_FILE, "w", encoding="utf-8") as f:
        json.dump(list(origins), f, ensure_ascii=False, indent=2)

@register("SEUåŠ©æ‰‹", "æ•™åŠ¡å¤„æ–°é—»è®¢é˜…ä¸æŸ¥è¯¢æ’ä»¶ï¼Œæ–°ç‰ˆæ”¯æŒå…³é”®è¯å’Œæ—¥æœŸæŸ¥è¯¢ï¼Œè‡ªåŠ¨è¾“å‡ºæœ€æ–°æ–°é—»åŠå…¨é‡æ›´æ–°", "1.0.1", "https://github.com/Last-emo-boy/seu-news-bot")
class NewsPlugin(Star):
    def __init__(self, context: Context, config: dict):
        """
        åˆå§‹åŒ–æ—¶æ¥æ”¶é…ç½®æ–‡ä»¶ï¼ˆé€šè¿‡ _conf_schema.jsonï¼‰ï¼Œé…ç½®é¡¹åŒ…æ‹¬ï¼š
          - check_interval: æ£€æŸ¥æ›´æ–°çš„é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 3600 ç§’
        """
        super().__init__(context)
        self.config = config
        self.db = NewsDB()
        # åŠ è½½æŒä¹…åŒ–çš„è‡ªåŠ¨é€šçŸ¥ä¼šè¯åˆ—è¡¨
        self.auto_notify_origins = load_auto_notify_origins()
        interval = self.config.get("check_interval", 3600)
        asyncio.create_task(self.scheduled_check(interval=interval))
    
    async def scheduled_check(self, interval: int):
        """
        å®šæ—¶ä»»åŠ¡ï¼šæ¯æ¬¡æ£€æŸ¥æ›´æ–°åï¼Œ
          è‹¥æ£€æµ‹åˆ°æ–°æ–°é—»ä¸”å­˜åœ¨è‡ªåŠ¨æ›´æ–°è®¢é˜…ä¼šè¯ï¼Œ
          åˆ™å‘æ‰€æœ‰è®¢é˜…ä¼šè¯æ¨é€æœ€æ–°æ–°é—»ã€‚
        """
        while True:
            new_news = await self.check_updates(force_update=False)
            if new_news and self.auto_notify_origins:
                msg_text = f"æ£€æµ‹åˆ° {len(new_news)} æ¡æ–°æ–°é—»ï¼š\n\n"
                for channel, title, url, pub_date in new_news:
                    msg_text += f"ã€{channel}ã€‘ {title}\né“¾æ¥ï¼š{url}\nå‘å¸ƒæ—¥æœŸï¼š{pub_date}\n\n"
                for origin in self.auto_notify_origins:
                    await self.context.send_message(origin, [Plain(msg_text)])
            await asyncio.sleep(interval)
    
    async def check_updates(self, force_update: bool = False):
        """
        æ›´æ–°æ–°é—»æ•°æ®ã€‚
        
        å‚æ•°:
          - force_update: è‹¥ä¸º Trueï¼Œåˆ™å…¨é‡æ›´æ–°ï¼ˆå¿½ç•¥å·²å­˜åœ¨æ–°é—»åˆ¤æ–­ï¼‰ï¼›å¦åˆ™é‡åˆ°å·²æœ‰æ–°é—»æ—¶åœæ­¢ç¿»é¡µæ›´æ–°ã€‚
        
        è¿”å›:
          è¿”å›æœ¬æ¬¡æ›´æ–°ä¸­æ–°æ’å…¥çš„æ–°é—»åˆ—è¡¨ï¼Œæ¯æ¡è®°å½•æ ¼å¼ä¸º (é¢‘é“, æ ‡é¢˜, é“¾æ¥, å‘å¸ƒæ—¥æœŸ)ã€‚
        """
        new_news_all = []
        async with aiohttp.ClientSession() as session:
            for path in PATHS:
                latest_date = None if force_update else self.db.get_latest_date(path)
                page = 1
                has_new = True
                while has_new:
                    url = f"{BASE_URL}/{path}/list{page}.htm"
                    async with session.get(url, headers=HEADERS) as resp:
                        if resp.status != 200:
                            break
                        html = await resp.text()
                        soup = BeautifulSoup(html, "html.parser")
                        news_div = soup.find("div", id="wp_news_w8")
                        if not news_div:
                            break
                        news_list = []
                        for tr in news_div.find_all("tr"):
                            title_tag = tr.find("a", title=True)
                            tds = tr.find_all("td", class_="main")
                            if title_tag and tds and len(tds) >= 2 and tds[1].find("div"):
                                pub_date_str = tds[1].find("div").text.strip()
                                try:
                                    pub_date = datetime.strptime(pub_date_str, "%Y-%m-%d")
                                    pub_date_iso = pub_date.isoformat()
                                except Exception:
                                    pub_date_iso = "æ—¥æœŸæœªçŸ¥"
                                if not force_update and latest_date not in (None, "æ—¥æœŸæœªçŸ¥") and pub_date_iso != "æ—¥æœŸæœªçŸ¥":
                                    try:
                                        latest_dt = datetime.fromisoformat(latest_date)
                                        if pub_date <= latest_dt:
                                            has_new = False
                                            break
                                    except Exception:
                                        pass
                                relative_url = title_tag.get("href", "")
                                full_url = relative_url if relative_url.startswith("http") else f"{BASE_URL}{relative_url}"
                                news_list.append((path, title_tag["title"].strip(), full_url, pub_date_iso))
                        if news_list:
                            self.db.insert_news(news_list)
                            new_news_all.extend(news_list)
                            if not force_update and latest_date is not None:
                                break
                            else:
                                page += 1
                        else:
                            break
        return new_news_all

    @filter.command("news")
    async def get_news(self, event: AstrMessageEvent, 
                       channel: str = None, 
                       page: int = 1, 
                       keyword: str = None, 
                       start_date: str = None, 
                       end_date: str = None):
        """
        è·å–æ•™åŠ¡å¤„æ–°é—»ã€‚
        
        å‚æ•°:
          - channel: å¯é€‰ï¼ŒæŒ‡å®šæ ç›®åç§°ï¼ˆå¦‚ zxdtã€jwxx ç­‰ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰ã€‚
          - page: é¡µç ï¼Œé»˜è®¤ 1ï¼Œæ¯é¡µæ˜¾ç¤º 5 æ¡æ–°é—»ã€‚
          - keyword: å¯é€‰ï¼Œæ–°é—»æ ‡é¢˜å…³é”®è¯è¿‡æ»¤ã€‚
          - start_date: å¯é€‰ï¼Œèµ·å§‹å‘å¸ƒæ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DDã€‚
          - end_date: å¯é€‰ï¼Œç»“æŸå‘å¸ƒæ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DDã€‚
        """
        per_page = 5
        news = self.db.get_news(channel=channel, page=page, per_page=per_page, 
                                keyword=keyword, start_date=start_date, end_date=end_date)
        if not news:
            yield event.plain_result("æš‚æ— æ›´å¤šæ–°é—»")
            return
        
        result = event.make_result().message(f"ğŸ“° æ–°é—»æŸ¥è¯¢ç»“æœï¼ˆç¬¬ {page} é¡µï¼‰\n")
        for idx, item in enumerate(news, 1):
            result = result.message(f"{idx}. ã€{item[0]}ã€‘{item[1]}\né“¾æ¥ï¼š{item[2]}\nå‘å¸ƒæ—¥æœŸï¼š{item[3]}\n\n")
        if len(news) == per_page:
            next_cmd = f"/news {channel or ''} {page+1} {keyword or ''} {start_date or ''} {end_date or ''}"
            result = result.message(f"å‘é€ {next_cmd.strip()} æŸ¥çœ‹ä¸‹ä¸€é¡µ")
        yield result

    @filter.command("news auto")
    async def news_auto_subscribe(self, event: AstrMessageEvent):
        """
        æŒ‡ä»¤: /news auto
        å°†å½“å‰ä¼šè¯åŠ å…¥åˆ°è‡ªåŠ¨æ›´æ–°é€šçŸ¥åˆ—è¡¨ï¼ˆæŒä¹…åŒ–ï¼‰ã€‚
        """
        origin = event.unified_msg_origin
        if origin in self.auto_notify_origins:
            yield event.plain_result("å½“å‰ä¼šè¯å·²åœ¨è‡ªåŠ¨æ›´æ–°åˆ—è¡¨ä¸­ã€‚")
        else:
            self.auto_notify_origins.add(origin)
            save_auto_notify_origins(self.auto_notify_origins)
            yield event.plain_result("å·²å°†å½“å‰ä¼šè¯åŠ å…¥è‡ªåŠ¨æ›´æ–°é€šçŸ¥åˆ—è¡¨ã€‚")

    @filter.command("news auto off")
    async def news_auto_unsubscribe(self, event: AstrMessageEvent):
        """
        æŒ‡ä»¤: /news auto off
        å°†å½“å‰ä¼šè¯ä»è‡ªåŠ¨æ›´æ–°é€šçŸ¥åˆ—è¡¨ä¸­ç§»é™¤ï¼ˆå¹¶æ›´æ–°æŒä¹…åŒ–å­˜å‚¨ï¼‰ã€‚
        """
        origin = event.unified_msg_origin
        if origin in self.auto_notify_origins:
            self.auto_notify_origins.remove(origin)
            save_auto_notify_origins(self.auto_notify_origins)
            yield event.plain_result("å·²å°†å½“å‰ä¼šè¯ç§»é™¤è‡ªåŠ¨æ›´æ–°é€šçŸ¥åˆ—è¡¨ã€‚")
        else:
            yield event.plain_result("å½“å‰ä¼šè¯ä¸åœ¨è‡ªåŠ¨æ›´æ–°åˆ—è¡¨ä¸­ã€‚")

    @filter.command("news update")
    async def news_update(self, event: AstrMessageEvent):
        """
        æŒ‡ä»¤: /news update
        å¼ºåˆ¶å…¨é‡æ›´æ–°æ–°é—»ï¼Œæ— è®ºæ•°æ®åº“ä¸­æ˜¯å¦å·²æ˜¯æœ€æ–°ï¼Œç„¶ååé¦ˆæ›´æ–°æ•°é‡ã€‚
        """
        new_news = await self.check_updates(force_update=True)
        msg = f"å…¨é‡æ›´æ–°å®Œæˆï¼Œå…±æ›´æ–° {len(new_news)} æ¡æ–°é—»ã€‚"
        yield event.plain_result(msg)
    
    async def terminate(self):
        self.db.close()
